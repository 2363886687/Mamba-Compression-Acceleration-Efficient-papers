# mamba-compression-acceleration-efficient-papers
## mamba compression

### Token reduction
R-MeeTo https://github.com/NUS-HPC-AI-Lab/R-MeeTo
  Token merging + Re-training
  Inspired by ToMe, in the token merging stage, this paper first divides tokens into odd and even sequence, then calculate their distance, and finally merge the most relevent r pairs. The Retraining stage extremely quickly restore the accuracy of the token merged model.

Famba-V （ECCV 2024） https://github.com/AIoT-MLSys-Lab/Famba-V
Also based on ToMe, this paper proposes a suit of cross-layer choice strategies in Vim.

### Quantization
PTQ4VM https://github.com/YoungHyun197/ptq4vm




### Structual pruning

### Application


## mamba acceleration



## efficient mamba
